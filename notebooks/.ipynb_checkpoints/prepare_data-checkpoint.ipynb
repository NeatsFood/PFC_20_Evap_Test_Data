{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import re\n",
    "import urllib.parse\n",
    "import datetime\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#### Read in the Excel data\n",
    "All the core data is stored in the `data/PFC_EVAP_DATASET_Jan-Feb_2019.xlsx`. This file contains data from running multiple grows in multiple Personal food computers to test the effects of air pump on evaporation of the water. \n",
    "\n",
    "There are multiple tabs in the `.xlsx` file:\n",
    "\n",
    " - Tab 0: Bot Mapping. This tab describes the set up of the 20 machines. (more detail below)\n",
    " - Tab 1: compile_manual_PFC_evap_201902_. This tab is a compilation of all the manual data that was recorded. (`dissolved_o2`, `height_cm`, `leaf_count`, `leaves_removed`, `harvest_fresh_mass_g`) Not all rows have all columns, missing data (or data not recorded) have `NA` as a value.\n",
    " - Tab 2: Water Level Notes. Notes taken about how much water was left at various intervals through out the process.\n",
    " - Tab 3: Images. A list of all images from the machines taken. The file format has Bot ID, Date, and Time (UTC) embeded in it\n",
    " - Tab 4: Raw Sensor Data. All sensor readings taken by the bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bot Mapping\n",
    "\n",
    "There are two different Device IDs for each bot, as short one, and a longer one. Since the various bits of data refere to one or another, we should make a map between the two, and in our analysis use only one. This data is in the first tab, with the short IDs being in `H4:H23` and the corrisponding long IDs being in `K4:K23`.\n",
    "\n",
    "It turns out that one of the short IDs is stored as a `float` in the bot mapping tab, but that is ok, because the short IDs are only really used in the compiled manual data, as well as the water level notes. This file only is using the manual data, and it happens to also be a `float` in that data as well. The output of this will be a single CSV for each bot of both manual and automatically recorded data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls_filename = \"../data/PFC_EVAP_DATASET_Jan-Feb_2019.xlsx\"\n",
    "workbook = xlrd.open_workbook(xls_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_mapping_sheet = workbook.sheet_by_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortIdsToLong = {}\n",
    "for i in range(3,23):\n",
    "    shortId = bot_mapping_sheet.cell_value(i,7)\n",
    "    longId = bot_mapping_sheet.cell_value(i,10)\n",
    "    shortIdsToLong[shortId] = longId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/csv/wifi_code_to_device_id.csv\",'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"wifi_code\",\"device_id\"])\n",
    "    for code in shortIdsToLong.keys():\n",
    "        writer.writerow([code,shortIdsToLong[code]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treatment lists\n",
    "Do a mapping from the shortId to the treatment used. Rather than parsing the data (as the a few of the values were interperated by Excel as scientific notation), just hard code it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments = {\"6F06\":\"No airtstone + normal fan speed\",\n",
    "              \"33B3\":\"No airtstone + normal fan speed\",\n",
    "              \"10CE\":\"No airtstone + normal fan speed\",\n",
    "              \"4FD3\":\"No airtstone + normal fan speed\",\n",
    "             \n",
    "             5093.0:\"Airstone + no fan speed\",\n",
    "             \"4DFA\":\"Airstone + no fan speed\",\n",
    "             \"5D93\":\"Airstone + no fan speed\",\n",
    "             \"F3D3\":\"Airstone + no fan speed\",\n",
    "             \n",
    "             \n",
    "             \"C202\":\"No airstone + no fan speed\",\n",
    "             \"49B3\":\"No airstone + no fan speed\",\n",
    "             \"5DAE\":\"No airstone + no fan speed\",\n",
    "             \"4B6B\":\"No airstone + no fan speed\",\n",
    "             \n",
    "             \n",
    "             \"FBC0\":\"Soil Germination + no fan + covered\",\n",
    "             \"82E9\":\"Soil Germination + no fan + covered\",\n",
    "             \"ACE4\":\"Soil Germination + no fan + covered\",\n",
    "             \"4DAF\":\"Soil Germination + no fan + covered\",\n",
    "             \n",
    "             \"51E6\":\"Control (fan + airstone)\",\n",
    "             \"8D63\":\"Control (fan + airstone)\",\n",
    "             \"DO62\":\"Control (fan + airstone)\",\n",
    "             \"7DB1\":\"Control (fan + airstone)\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes \n",
    "- In the manual data, we have D062 and DO62 (first has a zero, second has a cap o), looks like cap o didn't get used, so we can ignore it safely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual Bot CSV files\n",
    "\n",
    "Lets start to parse through the other data, and create three sets of CSV files, `bot_manual_data`, `bot_raw_data`, `bot_images`. Take this opportunity to normalize the times, as the raw data is in EST, but the rest is in UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLongIdMap():\n",
    "    returnMap = {}\n",
    "    for longId in shortIdsToLong.values():\n",
    "        returnMap[longId] = []\n",
    "    return returnMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data_by_bot = getLongIdMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in manual_data_by_bot.keys():\n",
    "    manual_data_by_bot[id].append([\"treatment\", \"date\", \"dissovled_o2\", \"height_cm\", \"leaf_count\", \"leaves_removed\", \"harvest_fresh_mass_g\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data_sheet = workbook.sheet_by_index(1)\n",
    "for i in range(manual_data_sheet.nrows):\n",
    "    row = manual_data_sheet.row_values(i)\n",
    "    if row[0] in shortIdsToLong.keys():\n",
    "        manual_data_by_bot[shortIdsToLong[row[0]]].append([treatments[row[0]],  # Treatment\n",
    "                                                      str(int(row[3])),              # Date\n",
    "                                                      row[4],              # Dissolved o2\n",
    "                                                      row[5],              # height_cm\n",
    "                                                      row[6],              # leaf_count\n",
    "                                                      row[7],              # leaves_removed\n",
    "                                                      row[8]])              # harvest_fresh_mass_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_by_bot = getLongIdMap()\n",
    "for id in images_by_bot.keys():\n",
    "    images_by_bot[id].append([\"date\",\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_sheet = workbook.sheet_by_index(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_filename_regex = r\"https.*images/(.*)_C.*_(.*Z).png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,images_sheet.nrows):\n",
    "    full_url = images_sheet.cell_value(i,0)\n",
    "    botId, date = re.match(image_filename_regex,full_url).groups()\n",
    "    images_by_bot[botId].append([urllib.parse.unquote(date), full_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convertEstToUtcStr(est_str):\n",
    "    inFormat = '%a %b %d %H:%M:%S %Y'\n",
    "    d = datetime.datetime.strptime(est_str,inFormat)\n",
    "    return d.astimezone(datetime.timezone.utc).isoformat().replace(\"+00:00\",\"Z\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_by_bot = getLongIdMap()\n",
    "for id in raw_data_by_bot.keys():\n",
    "    raw_data_by_bot[id].append([\"time_utc\",\"var\",\"name\",\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_sheet = workbook.sheet_by_index(4)\n",
    "for i in range(1,raw_data_sheet.nrows):\n",
    "    row = raw_data_sheet.row_values(i)\n",
    "    raw_data_by_bot[row[0]].append([convertEstToUtcStr(row[1])]+row[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write out the collected CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for botId in manual_data_by_bot.keys():\n",
    "    path = \"../data/csv/\"+botId\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs()\n",
    "    with open(os.path.join(path,\"raw_sensor_data.csv\"),'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(raw_data_by_bot[botId])\n",
    "    with open(os.path.join(path, \"manual_data.csv\"),'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(manual_data_by_bot[botId])\n",
    "    with open(os.path.join(path, \"image_urls.csv\"),'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(images_by_bot[botId])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook.release_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
