{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data downloaded from BigQuery\n",
    "\n",
    "The .xlsx file only had air sensor data in it for the PFC-EDU evaporation test that was run between Jan 15 and Feb 15. The raw data (with the exception of 'boot' and 'status' heart beat messages) have been pulled from BigQuery for the dates of the pilot and for the evaporation test.\n",
    "\n",
    "##### *NOTE*\n",
    "\n",
    "Not all 20 of the machines used in the evaporation test were also present in the pilot. A few of the BeagleBone boards that are the brains of the PFC-EDU were damaged beyond repair by the time the units were returned to us. while the 'brain board's from these machines (the circuit boards that have the LEDs and sensors on them) were re-used, the BeagleBones were replaced, generating new IDs in our back end.\n",
    "\n",
    "##### BQ CSV format\n",
    "The two CSV files that have been downloaded from BigQuery contain rows in the following format:\n",
    "`device`,`report_time`,`var`,`name`,`value`,`values`\n",
    "\n",
    "`var` is the actual value being measured/represented, `name` is the name of the sensor being used, `value` is a singular value while `values` is for data that is stored as a `json` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "evap_test_file = \"../data/csv/raw_from_BQ/bq-results-pfc-20-test-jan_14-feb_15.csv\"\n",
    "pilot_data_file = \"../data/csv/raw_from_BQ/bq-results-pfc-20-pilot-data-oct_11_2018-jan_1_2019.csv\"\n",
    "save_path = \"../data/csv/raw_from_BQ/split_datas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def genfilename(dev_id, varname):\n",
    "    return dev_id + \"_\" + varname[0] + \"_\" + varname[1] + \".csv\"\n",
    "\n",
    "device_ids = []\n",
    "current_device_id = \"\"\n",
    "sensor_files = {}\n",
    "with open(evap_test_file, 'r') as infile:\n",
    "    for line in infile.readlines():\n",
    "        linesplit = line.split(',')\n",
    "        dev_id = linesplit[0].strip()\n",
    "        if dev_id != \"device\":\n",
    "            if dev_id not in device_ids:\n",
    "                device_ids.append(dev_id)\n",
    "            report_time = linesplit[1].strip()\n",
    "            varname = linesplit[2:4]\n",
    "            value = linesplit[4].strip()\n",
    "            values_json = (\",\".join(linesplit[5:])).strip()\n",
    "            if genfilename(dev_id, varname) not in sensor_files.keys():\n",
    "                sensor_files[genfilename(dev_id, varname)] = open(save_path+\"/evap_test/\"+genfilename(dev_id, varname),'w')\n",
    "                sensor_files[genfilename(dev_id, varname)].write(\"variable,sensor_name,timestamp_utc,value,value_json\")\n",
    "            else:\n",
    "                newline = \",\".join(varname + [report_time,value,values_json])\n",
    "                sensor_files[genfilename(dev_id, varname)].write(newline+\"\\n\")\n",
    "            \n",
    "for f in sensor_files.values():\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "deviceID Found: EDU-27B1A1C6-f4-5e-ab-3b-35-dd\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sensor_files = {}\n",
    "with open(pilot_data_file, 'r') as infile:\n",
    "    for line in infile.readlines():\n",
    "        linesplit = line.split(',')\n",
    "        dev_id = linesplit[0].strip()\n",
    "        if dev_id != \"device\":\n",
    "            if dev_id not in device_ids:\n",
    "                print(\"deviceID Found: \" + dev_id)\n",
    "                device_ids.append(dev_id)\n",
    "            report_time = linesplit[1].strip()\n",
    "            varname = linesplit[2:4]\n",
    "            value = linesplit[4].strip()\n",
    "            values_json = (\",\".join(linesplit[5:])).strip()\n",
    "\n",
    "            if genfilename(dev_id, varname) not in sensor_files.keys():\n",
    "                sensor_files[genfilename(dev_id, varname)] = open(save_path+\"/pilot_data/\"+genfilename(dev_id, varname),'w')\n",
    "                sensor_files[genfilename(dev_id, varname)].write(\"variable,sensor_name,timestamp_utc,value,value_json\\n\")\n",
    "            else:\n",
    "                newline = \",\".join(varname + [report_time,value,values_json])\n",
    "                sensor_files[genfilename(dev_id, varname)].write(newline+\"\\n\")\n",
    "            \n",
    "for f in sensor_files.values():\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['EDU-30A77B2D-f4-5e-ab-64-50-92',\n 'EDU-30EB6274-f4-5e-ab-66-6f-05',\n 'EDU-32B65C51-50-65-83-d0-fb-bf',\n 'EDU-429A28CD-f4-5e-ab-3c-f3-d2',\n 'EDU-46CF2F54-f4-5e-ab-5d-fd-81',\n 'EDU-4EF485F5-f4-5e-ab-5b-10-cd',\n 'EDU-56F786AB-f4-5e-ab-5c-33-b2',\n 'EDU-90DB5116-50-65-83-e6-7d-b0',\n 'EDU-A3F734CE-f4-5e-ab-59-ac-e3',\n 'EDU-B373ACFF-f4-5e-ab-66-4b-6a',\n 'EDU-B4092A13-f4-5e-ab-5a-4d-f9',\n 'EDU-C9B9F1A0-f4-5e-ab-5b-4f-d2',\n 'EDU-D473FCE2-f4-5e-ab-65-8d-62',\n 'EDU-D834D808-f4-5e-ab-fa-82-e8',\n 'EDU-DC266DD8-f4-5e-ab-60-49-b2',\n 'EDU-E074D2DE-f4-5e-ab-3d-d0-61',\n 'EDU-F86DC2E3-50-65-83-d5-51-e5',\n 'EDU-FACAD357-f4-5e-ab-67-5d-92',\n 'EDU-27B1A1C6-f4-5e-ab-3b-35-dd']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "device_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "raw_data_suffixes = {\"air_co2\":         \"air_carbon_dioxide_ppm_T6713-Top.csv\",\n",
    "             \"air_RH\":          \"air_humidity_percent_SHT25-Top.csv\",\n",
    "             \"air_temp_C\":      \"air_temperature_celcius_SHT25-Top.csv\",\n",
    "             \"water_ec_ms_cm\":  \"water_electrical_conductivity_ms_cm_AtlasEC-Reservoir.csv\",\n",
    "             \"water_pH\":        \"water_potential_hydrogen_AtlasPH-Reservoir.csv\",\n",
    "             \"water_temp_C\":    \"water_temperature_celcius_AtlasTemp-Reservoir.csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pilot_path = save_path + \"/pilot_data/\" + device_ids[0] + \"_\" + raw_data_suffixes[\"air_co2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'../data/csv/raw_from_BQ/split_datas/pilot_data/EDU-30A77B2D-f4-5e-ab-64-50-92_air_carbon_dioxide_ppm_T6713-Top.csv'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "pilot_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Date ranges\n",
    "Read in the pilot data, and figure out the date ranges of the sensor readings for each bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dfs = []\n",
    "max_min_dates = {}\n",
    "for dev_id in device_ids:\n",
    "    for suffix in raw_data_suffixes.keys():\n",
    "        filename = save_path + \"/pilot_data/\"+dev_id + \"_\" + raw_data_suffixes[suffix]\n",
    "        if os.path.exists(filename):\n",
    "            # print(filename)\n",
    "            df = pd.read_csv(filename)\n",
    "            df['timestamp_utc'] = pd.to_datetime(df['timestamp_utc'])\n",
    "            dfs.append(df)\n",
    "    max_min_dates[dev_id] = {'max': dfs[0]['timestamp_utc'].max(),\n",
    "                             'min': dfs[0]['timestamp_utc'].min()}\n",
    "    for i in range(1, len(dfs)):\n",
    "        if dfs[i]['timestamp_utc'].max() > max_min_dates[dev_id]['max']:\n",
    "            max_min_dates[dev_id]['max'] = dfs[i]['timestamp_utc'].max()\n",
    "        if dfs[i]['timestamp_utc'].min() > max_min_dates[dev_id]['min']:\n",
    "            max_min_dates[dev_id]['min'] = dfs[i]['timestamp_utc'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "for dev_id in max_min_dates.keys():\n",
    "    lines.append(dev_id + \": \"+str(max_min_dates[dev_id]['min'])+\" to \"+str(max_min_dates[dev_id]['max']) + \"\\n\")\n",
    "with open('../data/dates_of_data_found_in_pilot_timeframe_Oct_2018-Dec_2018.txt','w') as f:\n",
    "    f.writelines(lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "EDU-30A77B2D-f4-5e-ab-64-50-92: 2018-11-29 14:40:52+00:00 to 2018-12-07 05:03:23+00:00\n\nEDU-30EB6274-f4-5e-ab-66-6f-05: 2018-11-29 21:06:45+00:00 to 2018-12-31 23:57:39+00:00\n\nEDU-32B65C51-50-65-83-d0-fb-bf: 2018-11-30 10:11:46+00:00 to 2018-12-31 23:57:39+00:00\n\nEDU-429A28CD-f4-5e-ab-3c-f3-d2: 2018-11-30 10:11:46+00:00 to 2018-12-31 23:57:39+00:00\n\nEDU-46CF2F54-f4-5e-ab-5d-fd-81: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:39+00:00\n\nEDU-4EF485F5-f4-5e-ab-5b-10-cd: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:39+00:00\n\nEDU-56F786AB-f4-5e-ab-5c-33-b2: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:40+00:00\n\nEDU-90DB5116-50-65-83-e6-7d-b0: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:40+00:00\n\nEDU-A3F734CE-f4-5e-ab-59-ac-e3: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:40+00:00\n\nEDU-B373ACFF-f4-5e-ab-66-4b-6a: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:40+00:00\n\nEDU-B4092A13-f4-5e-ab-5a-4d-f9: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:40+00:00\n\nEDU-C9B9F1A0-f4-5e-ab-5b-4f-d2: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:40+00:00\n\nEDU-D473FCE2-f4-5e-ab-65-8d-62: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:40+00:00\n\nEDU-D834D808-f4-5e-ab-fa-82-e8: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:40+00:00\n\nEDU-DC266DD8-f4-5e-ab-60-49-b2: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:40+00:00\n\nEDU-E074D2DE-f4-5e-ab-3d-d0-61: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:40+00:00\n\nEDU-F86DC2E3-50-65-83-d5-51-e5: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:40+00:00\n\nEDU-FACAD357-f4-5e-ab-67-5d-92: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:40+00:00\n\nEDU-27B1A1C6-f4-5e-ab-3b-35-dd: 2018-12-06 12:17:37+00:00 to 2018-12-31 23:57:40+00:00\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some data stats on each bot in Evap Test (PFC-20 Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "stats_dfs = {}\n",
    "for dev_id in device_ids:\n",
    "    dfs = {}\n",
    "    for suffix in raw_data_suffixes.keys():\n",
    "        filename = save_path + \"/evap_test/\"+dev_id + \"_\" + raw_data_suffixes[suffix]\n",
    "        if os.path.exists(filename):\n",
    "            # print(filename)\n",
    "            df = pd.read_csv(filename)\n",
    "            df['timestamp_utc'] = pd.to_datetime(df['timestamp_utc'])\n",
    "            df.set_index('timestamp_utc', inplace=True)\n",
    "            dfs[suffix] = df.copy()\n",
    "    # Do the stats here\n",
    "    stat_column_names = [\"Sensor\", \"Count\", \"Max\", \"Min\", \"Mean\", \"Median\", \"Standard Deviation\"]\n",
    "    stat_rows = []\n",
    "    total_count = 0\n",
    "    for key in raw_data_suffixes.keys():\n",
    "        if key in dfs.keys():\n",
    "            stats_row = [key,\n",
    "                         dfs[key][\"value\"].count(),\n",
    "                         dfs[key][\"value\"].max(),\n",
    "                         dfs[key][\"value\"].min(),\n",
    "                         dfs[key][\"value\"].mean(),\n",
    "                        dfs[key][\"value\"].median(),\n",
    "                        dfs[key][\"value\"].std()]\n",
    "            stat_rows.append(stats_row)\n",
    "            total_count += dfs[key][\"value\"].count()\n",
    "    stat_rows.append([\"Total Readings\", total_count,0,0,0,0,0])\n",
    "    stats_df = pd.DataFrame(stat_rows,columns=stat_column_names)\n",
    "    stats_dfs[dev_id] = stats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "summary_path = \"../data/evap_test_summary_by_bot/\"\n",
    "for key in stats_dfs.keys():\n",
    "    with open(summary_path + key + \"_summary.csv\",'w') as outfile:\n",
    "        outfile.write(stats_dfs[key].to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           Sensor  Count     Max     Min        Mean  Median  \\\n0         air_co2   6551  573.00     0.0  143.172340  139.00   \n1          air_RH   6564   45.00     7.0   20.193632   18.00   \n2      air_temp_C   6564   40.00    13.0   24.945460   25.00   \n3  water_ec_ms_cm   6555    1.65     0.0    0.923399    0.91   \n4        water_pH   6555    7.46     3.6    7.147216    7.17   \n5    water_temp_C   6556   28.92 -1023.0   18.577454   20.94   \n6  Total Readings  39345    0.00     0.0    0.000000    0.00   \n\n   Standard Deviation  \n0           80.315757  \n1            7.937771  \n2            4.329392  \n3            0.259811  \n4            0.213877  \n5           48.307948  \n6            0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sensor</th>\n      <th>Count</th>\n      <th>Max</th>\n      <th>Min</th>\n      <th>Mean</th>\n      <th>Median</th>\n      <th>Standard Deviation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>air_co2</td>\n      <td>6551</td>\n      <td>573.00</td>\n      <td>0.0</td>\n      <td>143.172340</td>\n      <td>139.00</td>\n      <td>80.315757</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>air_RH</td>\n      <td>6564</td>\n      <td>45.00</td>\n      <td>7.0</td>\n      <td>20.193632</td>\n      <td>18.00</td>\n      <td>7.937771</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>air_temp_C</td>\n      <td>6564</td>\n      <td>40.00</td>\n      <td>13.0</td>\n      <td>24.945460</td>\n      <td>25.00</td>\n      <td>4.329392</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>water_ec_ms_cm</td>\n      <td>6555</td>\n      <td>1.65</td>\n      <td>0.0</td>\n      <td>0.923399</td>\n      <td>0.91</td>\n      <td>0.259811</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>water_pH</td>\n      <td>6555</td>\n      <td>7.46</td>\n      <td>3.6</td>\n      <td>7.147216</td>\n      <td>7.17</td>\n      <td>0.213877</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>water_temp_C</td>\n      <td>6556</td>\n      <td>28.92</td>\n      <td>-1023.0</td>\n      <td>18.577454</td>\n      <td>20.94</td>\n      <td>48.307948</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>Total Readings</td>\n      <td>39345</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "stats_dfs['EDU-FACAD357-f4-5e-ab-67-5d-92']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}